{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data = [[-1, 2], [-.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=[5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.4, -7.6],\n",
       "       [-3.2,  5.2],\n",
       "       [-3. , 18. ],\n",
       "       [-2.6, 43.6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.125,  9.   ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将字符型转换成数值标签\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征专用编码\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热变量转换成哑变量\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据阈值二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据阈值分多份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"E:\\Download\\2019机器学习sklearn课堂\\3-Digit Recognizer\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方差过滤，方差太小表明没有太大影响\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var0 = selector.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 708)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找到特征方差中位数后再设为阈值可以过滤一半特征\n",
    "import numpy as np\n",
    "selectorm = VarianceThreshold(threshold=np.median(x.var().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352.286703180131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(x.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 392)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_varm = selectorm.fit_transform(x)\n",
    "X_varm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 685)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果是二分类，伯努利随机变量，若p=0.8\n",
    "X_bar = VarianceThreshold(.8 *(1 - .8)).fit_transform(x)\n",
    "X_bar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看相关性（标签-特征），卡方， F检验，互信息\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卡方不可计算负数，挑选最大K 卡方 的特征\n",
    "X_chi = SelectKBest(chi2, k=300).fit_transform(X_varm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chivalue, pvalues_chi = chi2(X=X_varm, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "k = chivalue.shape[0] - (pvalues_chi > .05).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F检验，有分类和回归\n",
    "from sklearn.feature_selection import f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#互信息法，有分类和回归\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44328993e-15, 1.44328993e-15, 1.44328993e-15, 2.38095238e-05,\n",
       "       1.19047619e-05, 1.44328993e-15, 2.38095238e-05, 1.19047619e-05,\n",
       "       1.44328993e-15, 4.76190476e-05, 1.19047619e-05, 5.95238095e-05,\n",
       "       1.19047619e-04, 2.38095238e-05, 4.76190476e-05, 5.95238095e-05,\n",
       "       3.57142857e-05, 9.52380952e-05, 1.19047619e-05, 3.57142857e-05,\n",
       "       1.19047619e-05, 9.52380952e-05, 9.52380952e-05, 4.76190476e-05,\n",
       "       1.66666667e-04, 1.30952381e-04, 1.78571429e-04, 2.50000000e-04,\n",
       "       2.85714286e-04, 2.02380952e-04, 3.57142857e-05, 4.76190476e-05,\n",
       "       3.57142857e-05, 1.19047619e-05, 1.19047619e-05, 1.19047619e-05,\n",
       "       3.57142857e-05, 4.76190476e-05, 4.76190476e-05, 5.95238095e-05,\n",
       "       1.54761905e-04, 1.54761905e-04, 3.45238095e-04, 4.40476190e-04,\n",
       "       3.09523810e-04, 3.69047619e-04, 2.97619048e-04, 2.26190476e-04,\n",
       "       1.42857143e-04, 1.07142857e-04, 4.76190476e-05, 3.57142857e-05,\n",
       "       1.19047619e-05, 1.19047619e-05, 1.19047619e-05, 8.33333333e-05,\n",
       "       9.52380952e-05, 1.78571429e-04, 1.54761905e-04, 2.61904762e-04,\n",
       "       2.97619048e-04, 3.92857143e-04, 4.40476190e-04, 4.04761905e-04,\n",
       "       3.57142857e-04, 3.09523810e-04, 2.26190476e-04, 1.66666667e-04,\n",
       "       8.33333333e-05, 9.52380952e-05, 1.44328993e-15, 1.44328993e-15,\n",
       "       2.38095238e-05, 1.44328993e-15, 1.30952381e-04, 1.54761905e-04,\n",
       "       1.78571429e-04, 2.38095238e-04, 3.21428571e-04, 2.73809524e-04,\n",
       "       3.21428571e-04, 4.04761905e-04, 3.45238095e-04, 3.80952381e-04,\n",
       "       2.97619048e-04, 3.57142857e-04, 7.14285714e-05, 8.33333333e-05,\n",
       "       1.30952381e-04, 1.19047619e-05, 1.44328993e-15, 1.19047619e-05,\n",
       "       2.38095238e-05, 1.07142857e-04, 2.14285714e-04, 2.73809524e-04,\n",
       "       3.21428571e-04, 2.85714286e-04, 3.33333333e-04, 3.45238095e-04,\n",
       "       3.45238095e-04, 2.85714286e-04, 2.61904762e-04, 3.21428571e-04,\n",
       "       1.78571429e-04, 2.26190476e-04, 8.33333333e-05, 3.57142857e-05,\n",
       "       1.44328993e-15, 2.38095238e-05, 1.19047619e-04, 3.57142857e-05,\n",
       "       1.54761905e-04, 2.14285714e-04, 1.54761905e-04, 1.90476190e-04,\n",
       "       1.78571429e-04, 1.90476190e-04, 1.54761905e-04, 2.85714286e-04,\n",
       "       1.54761905e-04, 3.45238095e-04, 2.85714286e-04, 2.38095238e-04,\n",
       "       1.07142857e-04, 1.54761905e-04, 8.33333333e-05, 2.38095238e-05,\n",
       "       3.57142857e-05, 3.57142857e-05, 1.07142857e-04, 2.02380952e-04,\n",
       "       2.50000000e-04, 1.54761905e-04, 2.02380952e-04, 7.14285714e-05,\n",
       "       9.52380952e-05, 1.90476190e-04, 2.50000000e-04, 2.97619048e-04,\n",
       "       2.50000000e-04, 2.26190476e-04, 2.85714286e-04, 2.26190476e-04,\n",
       "       4.76190476e-05, 9.52380952e-05, 3.57142857e-05, 1.19047619e-05,\n",
       "       1.07142857e-04, 7.14285714e-05, 1.07142857e-04, 2.61904762e-04,\n",
       "       9.52380952e-05, 2.50000000e-04, 1.42857143e-04, 9.52380952e-05,\n",
       "       3.21428571e-04, 4.04761905e-04, 3.92857143e-04, 2.02380952e-04,\n",
       "       1.42857143e-04, 2.85714286e-04, 4.76190476e-05, 3.57142857e-05,\n",
       "       8.33333333e-05, 1.19047619e-05, 1.19047619e-05, 4.76190476e-05,\n",
       "       8.33333333e-05, 2.14285714e-04, 2.50000000e-04, 3.33333333e-04,\n",
       "       2.61904762e-04, 2.14285714e-04, 1.66666667e-04, 3.33333333e-04,\n",
       "       5.00000000e-04, 2.02380952e-04, 2.50000000e-04, 3.92857143e-04,\n",
       "       1.66666667e-04, 1.07142857e-04, 5.95238095e-05, 4.76190476e-05,\n",
       "       5.95238095e-05, 1.19047619e-05, 1.07142857e-04, 1.07142857e-04,\n",
       "       1.78571429e-04, 2.97619048e-04, 3.33333333e-04, 2.73809524e-04,\n",
       "       2.14285714e-04, 2.97619048e-04, 3.57142857e-04, 3.92857143e-04,\n",
       "       5.59523810e-04, 3.57142857e-04, 3.21428571e-04, 2.14285714e-04,\n",
       "       1.19047619e-04, 1.07142857e-04, 4.76190476e-05, 3.57142857e-05,\n",
       "       1.44328993e-15, 5.95238095e-05, 9.52380952e-05, 1.78571429e-04,\n",
       "       3.09523810e-04, 2.02380952e-04, 2.85714286e-04, 2.14285714e-04,\n",
       "       2.61904762e-04, 3.57142857e-04, 6.78571429e-04, 3.69047619e-04,\n",
       "       3.69047619e-04, 2.14285714e-04, 1.07142857e-04, 1.30952381e-04,\n",
       "       9.52380952e-05, 7.14285714e-05, 1.44328993e-15, 1.19047619e-05,\n",
       "       8.33333333e-05, 1.07142857e-04, 1.07142857e-04, 2.38095238e-04,\n",
       "       9.52380952e-05, 3.69047619e-04, 2.85714286e-04, 2.97619048e-04,\n",
       "       5.35714286e-04, 3.45238095e-04, 3.33333333e-04, 2.26190476e-04,\n",
       "       2.85714286e-04, 2.02380952e-04, 2.14285714e-04, 3.57142857e-05,\n",
       "       9.52380952e-05, 4.76190476e-05, 4.76190476e-05, 7.14285714e-05,\n",
       "       9.52380952e-05, 2.38095238e-04, 1.78571429e-04, 9.52380952e-05,\n",
       "       2.26190476e-04, 2.02380952e-04, 3.21428571e-04, 2.50000000e-04,\n",
       "       2.02380952e-04, 4.28571429e-04, 3.09523810e-04, 2.50000000e-04,\n",
       "       1.19047619e-04, 7.14285714e-05, 5.95238095e-05, 5.95238095e-05,\n",
       "       1.44328993e-15, 1.44328993e-15, 4.76190476e-05, 1.07142857e-04,\n",
       "       5.95238095e-05, 1.90476190e-04, 1.30952381e-04, 1.66666667e-04,\n",
       "       1.54761905e-04, 2.61904762e-04, 1.90476190e-04, 4.04761905e-04,\n",
       "       4.64285714e-04, 2.61904762e-04, 2.61904762e-04, 2.26190476e-04,\n",
       "       2.14285714e-04, 1.19047619e-04, 8.33333333e-05, 4.76190476e-05,\n",
       "       1.44328993e-15, 1.19047619e-05, 5.95238095e-05, 7.14285714e-05,\n",
       "       7.14285714e-05, 2.14285714e-04, 2.02380952e-04, 2.97619048e-04,\n",
       "       1.42857143e-04, 1.66666667e-04, 2.26190476e-04, 3.69047619e-04,\n",
       "       4.04761905e-04, 3.69047619e-04, 4.04761905e-04, 1.90476190e-04,\n",
       "       2.26190476e-04, 9.52380952e-05, 1.30952381e-04, 1.44328993e-15,\n",
       "       1.44328993e-15, 1.44328993e-15, 4.76190476e-05, 3.57142857e-05,\n",
       "       7.14285714e-05, 2.14285714e-04, 1.54761905e-04, 1.78571429e-04,\n",
       "       2.73809524e-04, 3.45238095e-04, 5.23809524e-04, 4.64285714e-04,\n",
       "       4.16666667e-04, 2.14285714e-04, 1.78571429e-04, 3.45238095e-04,\n",
       "       2.50000000e-04, 5.95238095e-05, 8.33333333e-05, 3.57142857e-05,\n",
       "       4.76190476e-05, 7.14285714e-05, 1.07142857e-04, 1.90476190e-04,\n",
       "       1.78571429e-04, 1.78571429e-04, 2.61904762e-04, 2.97619048e-04,\n",
       "       5.35714286e-04, 5.23809524e-04, 4.76190476e-04, 2.50000000e-04,\n",
       "       2.38095238e-04, 8.33333333e-05, 8.33333333e-05, 3.57142857e-05,\n",
       "       4.76190476e-05, 1.44328993e-15, 1.44328993e-15, 2.38095238e-05,\n",
       "       7.14285714e-05, 1.54761905e-04, 1.54761905e-04, 3.69047619e-04,\n",
       "       3.92857143e-04, 3.57142857e-04, 2.38095238e-04, 2.73809524e-04,\n",
       "       2.61904762e-04, 2.61904762e-04, 2.26190476e-04, 1.07142857e-04,\n",
       "       4.76190476e-05, 4.76190476e-05, 1.19047619e-05, 1.19047619e-05,\n",
       "       1.44328993e-15, 4.76190476e-05, 9.52380952e-05, 2.85714286e-04,\n",
       "       2.50000000e-04, 3.21428571e-04, 2.73809524e-04, 1.07142857e-04,\n",
       "       1.19047619e-04, 1.30952381e-04, 3.57142857e-05, 3.57142857e-05,\n",
       "       8.33333333e-05, 1.44328993e-15, 1.44328993e-15, 2.38095238e-05,\n",
       "       4.76190476e-05, 7.14285714e-05, 1.54761905e-04, 1.30952381e-04,\n",
       "       2.38095238e-04, 1.07142857e-04, 4.76190476e-05, 1.19047619e-05,\n",
       "       4.76190476e-05, 2.38095238e-05, 3.57142857e-05, 3.57142857e-05,\n",
       "       2.38095238e-05, 3.57142857e-05, 2.38095238e-05, 1.19047619e-05,\n",
       "       2.38095238e-05, 1.44328993e-15, 1.44328993e-15, 1.19047619e-05])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC(X_varm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用嵌入法\n",
    "挑选特征 -> 生成模型评估，循环。\n",
    "带有特征重要性和惩罚项模型可以使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RFC(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xembed = SelectFromModel(rfc, threshold=0.001).fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xembed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 包装法\n",
    "特征选择和算法训练同时进行，使用一个目标函数来选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step表示每一步移除的特征数目\n",
    "selector1 = RFE(rfc, n_features_to_select=340, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector1.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " selector1.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30,\n",
       "       29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13,\n",
       "       12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  5,  5,\n",
       "        5,  5,  5,  5,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  8,\n",
       "        8,  8,  8,  8,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11,\n",
       "       11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19,\n",
       "       19, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22,\n",
       "       22, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 26, 26, 26, 26,\n",
       "       26, 26, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29,\n",
       "       29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32, 32, 32,\n",
       "       32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,\n",
       "       35, 35, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 38,\n",
       "       39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41,\n",
       "       41, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44,\n",
       "       44, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 45,\n",
       "       45, 45, 44, 44, 44, 44, 43, 43, 43, 42, 42, 42, 41, 41, 41, 40, 40,\n",
       "       40, 40, 39, 39, 38, 38, 38, 38, 37, 37, 37, 37, 37, 36, 36, 36, 35,\n",
       "       35, 35, 34, 34, 34, 33, 33, 33, 32, 32, 32, 32, 31, 31, 31, 31, 30,\n",
       "       30, 30, 30, 29, 29, 29, 28, 28, 27, 28, 27, 26, 27, 26, 25, 26, 25,\n",
       "       25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 24, 23, 23, 22, 22, 22, 22,\n",
       "       21, 21, 21, 20, 20, 20, 19, 19, 19, 18, 18, 18, 17, 17, 17, 16, 16,\n",
       "       16, 16, 15, 15, 14, 14, 14, 14, 13, 13, 13, 12, 12, 12, 11, 11, 11,\n",
       "       10, 10, 10,  9,  9,  9,  8,  8,  8,  8,  7,  7,  6,  6,  6,  6,  5,\n",
       "        5,  5,  4,  4,  4,  4,  3,  3,  3,  2,  2,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector1.ranking_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
